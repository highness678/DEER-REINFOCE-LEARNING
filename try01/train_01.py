import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor
from stable_baselines3.common.utils import set_random_seed
from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor, DummyVecEnv
import os

# å¯¼å…¥ä½ å†™å¥½çš„ç¯å¢ƒç±»
from env_sumo import SumoAVEnv

print("ã€è°ƒè¯• 1/4ã€‘ç¨‹åºå·²å¯åŠ¨ï¼Œæ­£åœ¨å‡†å¤‡ç¯å¢ƒ...") 

def make_env(rank, seed=0):
    """
    ç¯å¢ƒå·¥å‚å‡½æ•°ï¼šç”¨äºåˆ›å»ºç‹¬ç«‹çš„ç¯å¢ƒå®ä¾‹ã€‚
    
    Args:
        rank (int): è¿›ç¨‹çš„ç´¢å¼• (0, 1, 2, ...)
        seed (int): éšæœºç§å­
    """
    def _init():
        # 1. å®ä¾‹åŒ–ç¯å¢ƒ
        # æ³¨æ„ï¼šå¹¶è¡Œè®­ç»ƒæ—¶å¿…é¡»å…³é—­ GUI (use_gui=False)
        # è¿™é‡Œçš„ cfg è·¯å¾„å»ºè®®å†™ç»å¯¹è·¯å¾„ï¼Œæˆ–è€…ç¡®ä¿ç›¸å¯¹è·¯å¾„æ­£ç¡®
        print("ã€è°ƒè¯• 2/4ã€‘æ­£åœ¨å°è¯•å¯åŠ¨ SUMO ä»¿çœŸå™¨ï¼Œè¯·ç•™æ„ä»»åŠ¡æ æœ‰æ²¡æœ‰æ–°çª—å£...")
        env = SumoAVEnv(
            sumo_cfg_path="test.sumocfg", 
            use_gui=False,
            step_length=0.1,
            control_dt=0.5,
            max_steps=3600
        )
        
        # 2. è®¾ç½®éšæœºç§å­ (è®©æ¯ä¸ªç¯å¢ƒçš„éšæœºæ€§ç•¥æœ‰ä¸åŒï¼Œå¢åŠ æ¢ç´¢æ€§)
        env.reset(seed=seed + rank)
        return env
        
    return _init

print("ã€è°ƒè¯• 3/4ã€‘SUMO å¯åŠ¨æˆåŠŸï¼å‡†å¤‡å¼€å§‹è®­ç»ƒå¾ªç¯...")

if __name__ == "__main__":
    # ==========================================
    # ğŸ‘‡ è°ƒè¯•æ¨¡å¼ä¿®æ”¹å¼€å§‹
    # ==========================================
    
    # 1. æš‚æ—¶åªç”¨ 1 ä¸ª CPUï¼Œæ–¹ä¾¿çœ‹æŠ¥é”™
    num_cpu = 1 
    print(f"ã€è°ƒè¯•æ¨¡å¼ã€‘æ­£åœ¨å¯åŠ¨ {num_cpu} ä¸ª SUMO ç¯å¢ƒ...")

    # 2. ä¿®æ”¹ make_env é‡Œçš„å‚æ•°ç”¨äºè°ƒè¯•
    # æˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å·¥å‚å‡½æ•°ï¼Œå¼ºåˆ¶å¼€å¯ GUI
    def make_debug_env(rank, seed=0):
        def _init():
            print("ã€è°ƒè¯•ã€‘æ­£åœ¨å¯åŠ¨å¸¦ç•Œé¢çš„ SUMO...")
            # âš ï¸ æ³¨æ„ï¼šè¿™é‡ŒæŠŠ use_gui æ”¹æˆäº† Trueï¼Œè®©ä½ èƒ½çœ‹åˆ°ç”»é¢ï¼
            env = SumoAVEnv(
                sumo_cfg_path="test.sumocfg", 
                use_gui=True,  
                step_length=0.1,
                control_dt=0.5,
                max_steps=3600
            )
            return env
        return _init

    # 3. ä½¿ç”¨ DummyVecEnv (å•çº¿ç¨‹)ï¼Œè€Œä¸æ˜¯ SubprocVecEnv (å¤šè¿›ç¨‹)
    # è¿™æ ·æŠ¥é”™ä¼šç›´æ¥æ˜¾ç¤ºåœ¨ç»ˆç«¯ï¼Œä¸ä¼šè¢«éšè—
    env = DummyVecEnv([make_debug_env(0)])
    
    env = VecMonitor(env, filename="./logs/monitor_logs")

    # 4. å®šä¹‰æ¨¡å‹ - å…³é”®ä¿®æ”¹ï¼
    model = PPO(
        "MlpPolicy", 
        env, 
        verbose=1, 
        tensorboard_log="./logs/tensorboard",
        learning_rate=3e-4,
        batch_size=64,   # æ”¹å°
        n_steps=128,     # âš ï¸ æå…¶é‡è¦ï¼šæ”¹å°ï¼
                         # åªè¦è·‘ 128 æ­¥å°±ä¼šæ‰“å°ä¸€æ¬¡æ—¥å¿—ï¼Œä½ ä¼šç«‹åˆ»çœ‹åˆ°ååº”
        device="auto"
    )

    # 5. å¼€å§‹è®­ç»ƒ
    print("ã€è°ƒè¯•ã€‘å¼€å§‹è®­ç»ƒ... è¯·ç•™æ„å¼¹å‡ºçš„ SUMO çª—å£ï¼Œå¹¶ç‚¹å‡»æ’­æ”¾(Play)ï¼")
    model.learn(total_timesteps=10000)

    model.save("ppo_sumo_debug")
    print("è°ƒè¯•å®Œæˆã€‚")
    env.close()
